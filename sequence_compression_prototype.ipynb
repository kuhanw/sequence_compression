{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLSTMLayers(n_layers, n_cells, dropout):\n",
    "    cell_list = []\n",
    "    \n",
    "    for layer in range(n_layers):\n",
    "        cell = tf.contrib.rnn.LayerNormBasicLSTMCell(n_cells, activation=tf.nn.relu, layer_norm=False)\n",
    "        \n",
    "        cell_list.append(cell)\n",
    "        \n",
    "    return cell_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padSeq(seqs, pad_length, right_pad=True):\n",
    "    \n",
    "    '''\n",
    "    padSeq\n",
    "    \n",
    "    Pad sequences to be equal length.\n",
    "    \n",
    "    seqs: sequences to be padded\n",
    "    pad_length: length to pad sequences\n",
    "    left_pad: Pad at the end of the sequences, or reverse pad from front\n",
    "    '''\n",
    "    \n",
    "    padded_seqs = np.zeros((len(seqs), pad_length))\n",
    "    \n",
    "    for idx_row, row in enumerate(seqs):\n",
    "        for idx_col, col in enumerate(row):\n",
    "            if right_pad:\n",
    "                padded_seqs[idx_row, idx_col] = seqs[idx_row][idx_col]\n",
    "            else:\n",
    "                padded_seqs[idx_row, pad_length-idx_col-1] = seqs[idx_row][len(row)-idx_col-1]\n",
    "    return padded_seqs\n",
    "\n",
    "def generatePseudoSequences(seq_length, low, high, n_seqs, variable_length=False):\n",
    "    \n",
    "    '''\n",
    "    generatePseudoSequences\n",
    "    \n",
    "    seq_length: Length of sequence to generate\n",
    "    low: lower bound of values\n",
    "    high: upper bound of values\n",
    "    n_seqs: number of sequences to generate\n",
    "    variable_length: Create sequence of variable length    \n",
    "    '''\n",
    "    \n",
    "    #Generate random sequences\n",
    "    random_seqs = []\n",
    "    for seq in range(n_seqs):\n",
    "        if variable_length: current_length = random.randint(1, seq_length)\n",
    "        else: current_length = seq_length\n",
    "        current_seq = [random.randint(low, high) for _ in range(current_length)]\n",
    "        \n",
    "        random_seqs.append(current_seq)\n",
    "        \n",
    "    return random_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network parameters\n",
    "encoder_layers = 1\n",
    "encoder_cells = 5\n",
    "encoder_dropout = 1\n",
    "\n",
    "decoder_layers = 1\n",
    "decoder_cells = 5\n",
    "decoder_dropout = 1\n",
    "\n",
    "seq_length = 5\n",
    "n_features = 1\n",
    "\n",
    "latent_dimensions = 2\n",
    "\n",
    "#Training Parameters\n",
    "lr = 0.001\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(name='input', shape=[None, seq_length, n_features], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    q = sess.run([encoder_final_state], {inputs:[[[2.], [2.],[2.], [2.], [2.]]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder\n",
    "with tf.variable_scope('encoder', reuse=False):\n",
    "    \n",
    "    encoder_cell_fw = tf.contrib.rnn.MultiRNNCell(createLSTMLayers(encoder_layers, encoder_cells, encoder_dropout))\n",
    "    encoder_cell_bw = tf.contrib.rnn.MultiRNNCell(createLSTMLayers(encoder_layers, encoder_cells, encoder_dropout))\n",
    "    \n",
    "    (encoder_fw_outputs, encoder_bw_outputs), encoder_state_outputs = tf.nn.bidirectional_dynamic_rnn(\n",
    "                                        encoder_cell_fw,\n",
    "                                        encoder_cell_bw, \n",
    "                                        inputs=inputs,\n",
    "                                        dtype=tf.float32, time_major=False, swap_memory=True)\n",
    "    \n",
    "    encoder_final_state = tf.concat([state_tuple[0].h for state_tuple in encoder_state_outputs], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vector_in = tf.contrib.layers.fully_connected(encoder_final_state, latent_dimensions, activation_fn=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vector_out = tf.contrib.layers.fully_connected(latent_vector_in, decoder_cells, activation_fn=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = tf.zeros([tf.shape(inputs)[0], seq_length, n_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_initial_state = tuple([tf.nn.rnn_cell.LSTMStateTuple(c=latent_vector_out, h=latent_vector_out) for i in \n",
    "                              range(decoder_layers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder\n",
    "\n",
    "with tf.variable_scope('decoder', reuse=False):\n",
    "    \n",
    "    decoder_cell_fw = tf.contrib.rnn.MultiRNNCell(createLSTMLayers(decoder_layers, decoder_cells, decoder_dropout))\n",
    "    decoder_cell_bw = tf.contrib.rnn.MultiRNNCell(createLSTMLayers(decoder_layers, decoder_cells, decoder_dropout))\n",
    "    \n",
    "    (decoder_fw_outputs, decoder_bw_outputs), decoder_state_outputs = tf.nn.bidirectional_dynamic_rnn(\n",
    "                                        decoder_cell_fw,\n",
    "                                        decoder_cell_bw, \n",
    "                                        inputs=decoder_inputs,\n",
    "                                        initial_state_fw=decoder_initial_state,\n",
    "                                        initial_state_bw=decoder_initial_state,\n",
    "                                        dtype=tf.float32, time_major=False, swap_memory=True)\n",
    "    \n",
    "    decoder_outputs = tf.concat([decoder_fw_outputs, decoder_bw_outputs], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = tf.contrib.layers.fully_connected(decoder_outputs, n_features, activation_fn=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.square(inputs-output_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    q = sess.run([output_layer], {inputs:[[[2.], [2.], [2.], [2.], [2.]]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seqs = pd.DataFrame(padSeq(generatePseudoSequences(5, 1, 10, 10000, variable_length=True), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = model_selection.train_test_split(df_seqs, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "n_batches = df_train.shape[0]//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 250\n"
     ]
    }
   ],
   "source": [
    "print (n_epochs, n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  1.],\n",
       "        [  7.],\n",
       "        [  6.],\n",
       "        [  8.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  8.],\n",
       "        [  5.],\n",
       "        [  9.],\n",
       "        [  1.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[ 10.],\n",
       "        [  0.],\n",
       "        [  0.],\n",
       "        [  0.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  2.],\n",
       "        [  3.],\n",
       "        [  1.],\n",
       "        [  0.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  8.],\n",
       "        [  2.],\n",
       "        [ 10.],\n",
       "        [  0.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  8.],\n",
       "        [  4.],\n",
       "        [  4.],\n",
       "        [ 10.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  8.],\n",
       "        [  3.],\n",
       "        [  0.],\n",
       "        [  0.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  9.],\n",
       "        [  0.],\n",
       "        [  0.],\n",
       "        [  0.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  3.],\n",
       "        [  0.],\n",
       "        [  0.],\n",
       "        [  0.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  8.],\n",
       "        [  9.],\n",
       "        [  7.],\n",
       "        [  7.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  9.],\n",
       "        [  9.],\n",
       "        [  5.],\n",
       "        [  7.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[ 10.],\n",
       "        [  8.],\n",
       "        [ 10.],\n",
       "        [  9.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  5.],\n",
       "        [  4.],\n",
       "        [  1.],\n",
       "        [  6.],\n",
       "        [  3.]],\n",
       "\n",
       "       [[  1.],\n",
       "        [  1.],\n",
       "        [ 10.],\n",
       "        [  0.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  5.],\n",
       "        [  5.],\n",
       "        [  0.],\n",
       "        [  0.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  4.],\n",
       "        [  3.],\n",
       "        [  5.],\n",
       "        [  1.],\n",
       "        [  3.]],\n",
       "\n",
       "       [[  9.],\n",
       "        [  0.],\n",
       "        [  0.],\n",
       "        [  0.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  7.],\n",
       "        [ 10.],\n",
       "        [  5.],\n",
       "        [  9.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  8.],\n",
       "        [  2.],\n",
       "        [  0.],\n",
       "        [  0.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[ 10.],\n",
       "        [  2.],\n",
       "        [  4.],\n",
       "        [  9.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  4.],\n",
       "        [  0.],\n",
       "        [  0.],\n",
       "        [  0.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  7.],\n",
       "        [  0.],\n",
       "        [  0.],\n",
       "        [  0.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  4.],\n",
       "        [  1.],\n",
       "        [  3.],\n",
       "        [  6.],\n",
       "        [  8.]],\n",
       "\n",
       "       [[  6.],\n",
       "        [  7.],\n",
       "        [  0.],\n",
       "        [  0.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  8.],\n",
       "        [  8.],\n",
       "        [  2.],\n",
       "        [  2.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  4.],\n",
       "        [  9.],\n",
       "        [  0.],\n",
       "        [  0.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  5.],\n",
       "        [  6.],\n",
       "        [  8.],\n",
       "        [  4.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  9.],\n",
       "        [ 10.],\n",
       "        [  9.],\n",
       "        [  9.],\n",
       "        [  9.]],\n",
       "\n",
       "       [[  8.],\n",
       "        [  8.],\n",
       "        [  7.],\n",
       "        [  9.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  1.],\n",
       "        [  3.],\n",
       "        [  7.],\n",
       "        [  0.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[  5.],\n",
       "        [  5.],\n",
       "        [ 10.],\n",
       "        [  0.],\n",
       "        [  0.]],\n",
       "\n",
       "       [[ 10.],\n",
       "        [  7.],\n",
       "        [  1.],\n",
       "        [  2.],\n",
       "        [  0.]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training\n",
      "epoch:0, batch:0, loss:4.7e+03\n",
      "epoch:0, batch:100, loss:1.12e+03\n",
      "epoch:0, batch:200, loss:1.08e+03\n",
      "epoch:1, batch:0, loss:947\n",
      "epoch:1, batch:100, loss:753\n",
      "epoch:1, batch:200, loss:821\n",
      "epoch:2, batch:0, loss:767\n",
      "epoch:2, batch:100, loss:666\n",
      "epoch:2, batch:200, loss:486\n",
      "epoch:3, batch:0, loss:587\n",
      "epoch:3, batch:100, loss:593\n",
      "epoch:3, batch:200, loss:746\n",
      "epoch:4, batch:0, loss:603\n",
      "epoch:4, batch:100, loss:687\n",
      "epoch:4, batch:200, loss:645\n",
      "epoch:5, batch:0, loss:724\n",
      "epoch:5, batch:100, loss:463\n",
      "epoch:5, batch:200, loss:691\n",
      "epoch:6, batch:0, loss:542\n",
      "epoch:6, batch:100, loss:574\n",
      "epoch:6, batch:200, loss:576\n",
      "epoch:7, batch:0, loss:473\n",
      "epoch:7, batch:100, loss:524\n",
      "epoch:7, batch:200, loss:557\n",
      "epoch:8, batch:0, loss:676\n",
      "epoch:8, batch:100, loss:536\n",
      "epoch:8, batch:200, loss:556\n",
      "epoch:9, batch:0, loss:524\n",
      "epoch:9, batch:100, loss:532\n",
      "epoch:9, batch:200, loss:621\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print ('Begin training')\n",
    "    \n",
    "    for c_epoch in range(n_epochs):\n",
    "        df_epoch_samples = df_train.sample(frac=1)\n",
    "        for c_batch in range(n_batches): \n",
    "            batch = df_epoch_samples[c_batch*batch_size:(c_batch+1)*batch_size].values\n",
    "            batch = batch.reshape(len(batch), seq_length, 1)\n",
    "            _, c_loss = sess.run([optimizer, loss], {inputs:batch})\n",
    "            \n",
    "            if c_batch%100==0:\n",
    "                print ('epoch:%d, batch:%d, loss:%.3g' % (c_epoch, c_batch, c_loss))\n",
    "    \n",
    "    latent_vectors = sess.run(latent_vector_in, {inputs:df_train.values.reshape(df_train.shape[0], seq_length, 1)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAJCCAYAAADky0LWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ae80c2beb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Analysis\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(latent_vectors[:,0], latent_vectors[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
